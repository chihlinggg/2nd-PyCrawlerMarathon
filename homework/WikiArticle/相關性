[<p>在<a href="/wiki/%E6%A6%82%E7%8E%87%E8%AE%BA" title="概率論">概率論</a>和<a href="/wiki/%E7%BB%9F%E8%AE%A1%E5%AD%A6" title="統計學">統計學</a>中，<b>相關</b>（Correlation），顯示兩個<a href="/wiki/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F" title="隨機變量">隨機變量</a>之間線性關係的強度和方向。在統計學中，相關的意義是用來衡量兩個變量相對於其相互獨立的距離。在這個廣義的定義下，有許多根據數據特點而定義的用來衡量數據相關的係數。
</p>, <p>英國生物學家和統計學家<a class="mw-redirect" href="/wiki/%E5%BC%97%E6%9C%97%E8%A5%BF%E6%96%AF%C2%B7%E9%AB%98%E5%B0%94%E9%A1%BF" title="弗朗西斯·高爾頓">弗朗西斯·高爾頓</a>首先提出「相關」這一概念，英國數學家<a href="/wiki/%E5%8D%A1%E5%B0%94%C2%B7%E7%9A%AE%E5%B0%94%E9%80%8A" title="卡爾·皮爾遜">卡爾·皮爾遜</a>在此基礎上做出了進一步發展。
</p>, <p>對於不同<a href="/wiki/%E6%B8%AC%E9%87%8F%E5%B0%BA%E5%BA%A6" title="測量尺度">測量尺度</a>的變數，有不同的相關係數可用：
</p>, <p>其中，<i>E</i>是<a class="mw-redirect" href="/wiki/%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B" title="數學期望">數學期望</a>，cov表示<a href="/wiki/%E5%8D%8F%E6%96%B9%E5%B7%AE" title="共變異數">共變異數</a>，<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \sigma _{X}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>σ<!-- σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>X</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \sigma _{X}}</annotation>
</semantics>
</math></span><img alt="\sigma _{X}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/380c53c60c8301a5c80924b66363d831dfa80b9b" style="vertical-align: -0.671ex; width:2.96ex; height:2.009ex;"/></span>和<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \sigma _{Y}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>σ<!-- σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>Y</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \sigma _{Y}}</annotation>
</semantics>
</math></span><img alt="\sigma _{Y}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6a9fb889441f514e155f65e77dc5b7c7a5a84f35" style="vertical-align: -0.671ex; width:2.814ex; height:2.009ex;"/></span>是<a href="/wiki/%E6%A8%99%E6%BA%96%E5%B7%AE" title="標準差">標準差</a>。
</p>, <p>因為<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mu _{X}=E(X)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>μ<!-- μ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>X</mi>
</mrow>
</msub>
<mo>=</mo>
<mi>E</mi>
<mo stretchy="false">(</mo>
<mi>X</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mu _{X}=E(X)}</annotation>
</semantics>
</math></span><img alt="\mu _{X}=E(X)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1d889bd192ef195a3c839037a434d934de150759" style="vertical-align: -0.838ex; width:11.697ex; height:2.843ex;"/></span>，<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \sigma _{X}^{2}=E(X^{2})-E^{2}(X)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msubsup>
<mi>σ<!-- σ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>X</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msubsup>
<mo>=</mo>
<mi>E</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>X</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<msup>
<mi>E</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo stretchy="false">(</mo>
<mi>X</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \sigma _{X}^{2}=E(X^{2})-E^{2}(X)}</annotation>
</semantics>
</math></span><img alt="\sigma _{X}^{2}=E(X^{2})-E^{2}(X)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6ffb8a72219cb6a07e2e0dc29fa73042e0fa31df" style="vertical-align: -1.005ex; width:22.172ex; height:3.343ex;"/></span>，同樣地，對於<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Y}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>Y</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
</semantics>
</math></span><img alt="Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;"/></span>，可以寫成
</p>, <p>當兩個變量的<a href="/wiki/%E6%A8%99%E6%BA%96%E5%B7%AE" title="標準差">標準差</a>都不為零，相關係數才有定義。從<a href="/wiki/%E6%9F%AF%E8%A5%BF-%E6%96%BD%E7%93%A6%E8%8C%A8%E4%B8%8D%E7%AD%89%E5%BC%8F" title="柯西-施瓦茨不等式">柯西-施瓦茨不等式</a>可知，相關係數的<a class="mw-redirect" href="/wiki/%E7%B5%95%E5%B0%8D%E5%80%BC" title="絕對值">絕對值</a>不超過1。當兩個變量的線性關係增強時，相關係數趨於1或-1。當一個變量增加而另一變量也增加時，相關係數大於0。當一個變量的增加而另一變量減少時，相關係數小於0。當兩個變量獨立時，相關係數為0，但反之並不成立。這是因為相關係數僅僅反映了兩個變量之間是否線性相關。比如說，<i>X</i>是區間［－1，1］上的一個均勻分布的隨機變量。<i>Y</i> = <i>X</i><sup>2</sup>.那麼<i>Y</i>是完全由<i>X</i>確定。因此<i>Y</i>和<i>X</i>不獨立，但相關係數為0。或者說他們是不相關的。當<i>Y</i>和<i>X</i>服從聯合常態分布時，其相互獨立和不相關是等價的。
</p>, <p>當一個或兩個變量帶有測量誤差時，他們的相關性就受到削弱，這時，「反衰減」性（disattenuation）是一個更準確的係數。
</p>, <p>對於居中的數據來說（何謂居中？也就是每個數據減去樣本均值，居中後它們的平均值就為0），相關係數可以看作是兩個隨機變量中得到的樣本集向量之間夾角的cosine函數。一些實際工作者更喜歡用非居中的相關係數（與皮爾遜係數不相兼容）。看下面的例子中有一個比較。例如，假設五個國家的國民生產總值分別是1、2、3、5、8（單位10億美元），又假設這五個國家的貧困比例分別是11%、12%、13%、15%、18%。則我們現在有兩個有序的包含5個元素的向量x、y：x =（1, 2, 3, 5, 8）、 y =（0.11, 0.12, 0.13, 0.15, 0.18）
使用一般的方法來計算向量間夾角（參考<a class="mw-redirect" href="/wiki/%E6%95%B0%E9%87%8F%E7%A7%AF" title="數量積">數量積</a>），未居中的相關性係數如下：
</p>, <p>上面的數據實際上是故意選擇了一個完美的線性關係：y = 0.10 + 0.01 x。因此皮爾遜相關係數應該就是1。把數據居中（x中數據減去E (x) = 3.8，y中數據減去E (y) = 0.138）後得到：x =（−2.8, −1.8, −0.8, 1.2, 4.2）、y =（−0.028, −0.018, −0.008, 0.012, 0.042），由此得到了預期結果：
</p>, <p>相關係數的計算過程可表示為：將每個變量都轉化為標準單位，乘積的平均數即為相關係數<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup>。
</p>, <p>兩個變量的關係可以直觀地用散點圖表示，當其緊密地群聚於一條直線的周圍時，變量間存在強相關<sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup>。
</p>, <p>一個散點圖可以用五個統計量來概括。所有x值得平均數，所有x值的SD，所有y值得平均數，所有y值的SD，相關係數r.
</p>, <p>將第一個變量記為x ,第二個變量記為y ,相關係數為r，則可以通過以下公式：
</p>, <p>r = [（以標準單位表示的x）X（以標準單位表示的y）]的平均數
</p>]